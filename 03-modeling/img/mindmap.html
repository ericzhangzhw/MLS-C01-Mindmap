<!doctype html>
<html>
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
html {
  font-family: ui-sans-serif, system-ui, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.markmap-dark {
  background: #27272a;
  color: white;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.18.12/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/index.js"></script><script>((r) => {
          setTimeout(r);
        })(() => {
  const { markmap, mm } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute("style", "position:absolute;bottom:20px;right:20px");
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
              if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
                document.documentElement.classList.add("markmap-dark");
              }
            })(() => window.markmap,null,{"content":"Domain 3: Modeling (36% of Exam)","children":[{"content":"Task Statement 3.1: ML Problem Framing","children":[{"content":"1. The ML Pipeline Context","children":[{"content":"<strong>Previous Step (Domain 2)</strong>: Data Preprocessing &amp; Visualization","children":[],"payload":{"tag":"li","lines":"13,14"}},{"content":"<strong>Current Step (This Course)</strong>: Building, Training &amp; Testing the ML Model","children":[],"payload":{"tag":"li","lines":"14,15"}},{"content":"<strong>Exam Focus</strong>: Choosing the right algorithm for a business use case and knowing its performance metrics.","children":[],"payload":{"tag":"li","lines":"15,17"}}],"payload":{"tag":"h3","lines":"12,13"}},{"content":"2. When to Use and Not to Use ML","children":[{"content":"When ML Might Be a Good Fit","children":[{"content":"<strong>Requires Significant Data</strong>: ML needs large datasets to build a predictable model.","children":[],"payload":{"tag":"li","lines":"20,21"}},{"content":"<strong>Requires Expertise</strong>: Needs data processing and feature engineering to handle noise and retain meaningful information.","children":[],"payload":{"tag":"li","lines":"21,22"}},{"content":"<strong>Requires Powerful &amp; Scalable Machines</strong>: Needs computational power to crunch data and scale as data grows.","children":[],"payload":{"tag":"li","lines":"22,24"}}],"payload":{"tag":"h4","lines":"19,20"}},{"content":"When ML is NOT the Right Solution","children":[{"content":"<strong>Mission-Critical Applications</strong>: Scenarios where prediction errors are unacceptable.","children":[],"payload":{"tag":"li","lines":"25,26"}},{"content":"<strong>Simple Problems</strong>: Can be solved with simple rules and traditional programming (e.g., rule engines).","children":[],"payload":{"tag":"li","lines":"26,27"}},{"content":"<strong>Be Cognizant</strong>: ML is an expensive solution; ensure it&apos;s the right choice.","children":[],"payload":{"tag":"li","lines":"27,29"}}],"payload":{"tag":"h4","lines":"24,25"}}],"payload":{"tag":"h3","lines":"17,18"}},{"content":"3. Identifying the Right Learning Type","children":[{"content":"Supervised Learning &#x1f468;&#x200d;&#x1f3eb;","children":[{"content":"<strong>Analogy</strong>: A child learning under the guidance of a teacher.","children":[],"payload":{"tag":"li","lines":"32,33"}},{"content":"<strong>Data</strong>: Uses <strong>labeled training data</strong> (the outcome is already known).","children":[],"payload":{"tag":"li","lines":"33,34"}},{"content":"<strong>Goal</strong>: Model the relationship between inputs and outputs to predict new outcomes.","children":[],"payload":{"tag":"li","lines":"34,36"}}],"payload":{"tag":"h4","lines":"31,32"}},{"content":"Unsupervised Learning &#x1f575;&#xfe0f;","children":[{"content":"<strong>Analogy</strong>: A child figuring things out without supervision.","children":[],"payload":{"tag":"li","lines":"37,38"}},{"content":"<strong>Data</strong>: Deals with <strong>unlabeled data</strong>.","children":[],"payload":{"tag":"li","lines":"38,39"}},{"content":"<strong>Goal</strong>: Discover hidden structures, patterns, or information on its own.","children":[],"payload":{"tag":"li","lines":"39,41"}}],"payload":{"tag":"h4","lines":"36,37"}},{"content":"Reinforcement Learning &#x1f916;","children":[{"content":"<strong>Analogy</strong>: Rewarding a kid for good behavior to reinforce it.","children":[],"payload":{"tag":"li","lines":"42,43"}},{"content":"<strong>Core Idea</strong>: An autonomous agent learns through trial and error in an interactive environment.","children":[],"payload":{"tag":"li","lines":"43,44"}},{"content":"<strong>Use Cases</strong>: Self-driving vehicles, robotics, dynamic pricing.","children":[],"payload":{"tag":"li","lines":"44,46"}}],"payload":{"tag":"h4","lines":"41,42"}}],"payload":{"tag":"h3","lines":"29,30"}},{"content":"4. Selecting the Right Model Type","children":[{"content":"Classification","children":[{"content":"<strong>Use Case</strong>: When the dependent feature is categorical (discrete classes).","children":[],"payload":{"tag":"li","lines":"49,50"}},{"content":"<strong>Types</strong>: Binary, Multiclass, Multilabel.","children":[],"payload":{"tag":"li","lines":"50,51"}},{"content":"<strong>Challenge</strong>: Imbalanced Data (Solved with <strong>SMOTE</strong>).","children":[],"payload":{"tag":"li","lines":"51,52"}},{"content":"<strong>Common Algorithms</strong>: Logistic Regression, Naive Bayes, SVM, KNN.","children":[],"payload":{"tag":"li","lines":"52,54"}}],"payload":{"tag":"h4","lines":"48,49"}},{"content":"Regression","children":[{"content":"<strong>Use Case</strong>: When the target feature is quantitative or continuous.","children":[],"payload":{"tag":"li","lines":"55,56"}},{"content":"<strong>Example</strong>: Predicting house prices.","children":[],"payload":{"tag":"li","lines":"56,57"}},{"content":"<strong>Variations</strong>: Linear, Multiple, Polynomial Regression.","children":[],"payload":{"tag":"li","lines":"57,59"}}],"payload":{"tag":"h4","lines":"54,55"}},{"content":"Time Series Forecasting &#x1f4c8;","children":[{"content":"<strong>Use Case</strong>: For data collected at regular time intervals.","children":[],"payload":{"tag":"li","lines":"60,61"}},{"content":"<strong>Key Feature</strong>: <strong>Time</strong> is always an independent feature.","children":[],"payload":{"tag":"li","lines":"61,62"}},{"content":"<strong>Core Components</strong>: Trend, Seasonality, Cyclical Variations, Irregularity.","children":[],"payload":{"tag":"li","lines":"62,64"}}],"payload":{"tag":"h4","lines":"59,60"}},{"content":"Clustering","children":[{"content":"<strong>Type</strong>: Unsupervised learning.","children":[],"payload":{"tag":"li","lines":"65,66"}},{"content":"<strong>Goal</strong>: Group similar data points into clusters.","children":[],"payload":{"tag":"li","lines":"66,67"}},{"content":"<strong>Categories</strong>: Centroid-based (K-Means), Density-based (DBScan), Hierarchical.","children":[],"payload":{"tag":"li","lines":"67,69"}}],"payload":{"tag":"h4","lines":"64,65"}},{"content":"Association Learning","children":[{"content":"<strong>Type</strong>: Unsupervised learning.","children":[],"payload":{"tag":"li","lines":"70,71"}},{"content":"<strong>Goal</strong>: Discover &quot;if-then&quot; relationships between features.","children":[],"payload":{"tag":"li","lines":"71,72"}},{"content":"<strong>Use Cases</strong>: Market basket analysis, recommendation systems.","children":[],"payload":{"tag":"li","lines":"72,74"}}],"payload":{"tag":"h4","lines":"69,70"}},{"content":"Advanced: Deep Learning &amp; Neural Networks &#x1f9e0;","children":[{"content":"<strong>Purpose</strong>: A subset of ML for large/complex data and non-linear relationships.","children":[],"payload":{"tag":"li","lines":"75,76"}},{"content":"<strong>CNN (Convolutional Neural Networks)</strong>: For image/video processing.","children":[],"payload":{"tag":"li","lines":"76,77"}},{"content":"<strong>RNN (Recurrent Neural Networks)</strong>: For sequential data (text, time series). Includes LSTM &amp; GRU.","children":[],"payload":{"tag":"li","lines":"77,78"}},{"content":"<strong>Transfer Learning</strong>: Reusing a pre-trained model on a new, related task to save resources and improve performance.","children":[],"payload":{"tag":"li","lines":"78,80"}}],"payload":{"tag":"h4","lines":"74,75"}}],"payload":{"tag":"h3","lines":"46,47"}}],"payload":{"tag":"h2","lines":"10,11"}},{"content":"Task Statement 3.2: Amazon SageMaker Built-in Algorithms","children":[{"content":"1. Introduction to the SageMaker Ecosystem","children":[{"content":"<strong>Overview</strong>: A fully managed service to prepare, build, train, and deploy ML models at scale.","children":[],"payload":{"tag":"li","lines":"85,86"}},{"content":"<strong>Data Collection</strong>: <strong>SageMaker Ground Truth</strong> for data labeling.","children":[],"payload":{"tag":"li","lines":"86,87"}},{"content":"<strong>Data Analysis/Prep</strong>:","children":[{"content":"<strong>SageMaker Data Wrangler</strong>: Visualize and prepare data with no code.","children":[],"payload":{"tag":"li","lines":"88,89"}},{"content":"<strong>SageMaker Feature Store</strong>: Store and retrieve features for model development.","children":[],"payload":{"tag":"li","lines":"89,90"}}],"payload":{"tag":"li","lines":"87,90"}},{"content":"<strong>Model Building</strong>:","children":[{"content":"<strong>SageMaker Notebooks</strong>: Managed Jupyter Notebooks.","children":[],"payload":{"tag":"li","lines":"91,92"}},{"content":"<strong>SageMaker Studio</strong>: An IDE for the entire ML lifecycle.","children":[],"payload":{"tag":"li","lines":"92,93"}}],"payload":{"tag":"li","lines":"90,93"}},{"content":"<strong>Model Training</strong>:","children":[{"content":"<strong>Options</strong>: Use built-in algorithms, script mode (scikit-learn, PyTorch), or a custom Docker image.","children":[],"payload":{"tag":"li","lines":"94,95"}},{"content":"<strong>Architecture</strong>:","children":[{"content":"Training data stored in <strong>S3</strong>.","children":[],"payload":{"tag":"li","lines":"96,97"}},{"content":"Training job runs on <strong>SageMaker compute instances</strong>.","children":[],"payload":{"tag":"li","lines":"97,98"}},{"content":"Training job stored in <strong>Amazon ECR</strong>.","children":[],"payload":{"tag":"li","lines":"98,99"}},{"content":"Model output stored in another <strong>S3 bucket</strong>.","children":[],"payload":{"tag":"li","lines":"99,100"}},{"content":"<em>Constraint</em>: Training data and job must be in the same AWS region.","children":[],"payload":{"tag":"li","lines":"100,101"}}],"payload":{"tag":"li","lines":"95,101"}}],"payload":{"tag":"li","lines":"93,101"}},{"content":"<strong>Model Deployment</strong>:","children":[{"content":"<strong>SageMaker Hosting Services</strong>: For real-time inference with low latency.","children":[],"payload":{"tag":"li","lines":"102,103"}},{"content":"<strong>SageMaker Batch Transform</strong>: For asynchronous batch inference.","children":[],"payload":{"tag":"li","lines":"103,104"}}],"payload":{"tag":"li","lines":"101,104"}},{"content":"<strong>Model Monitoring</strong>:","children":[{"content":"<strong>SageMaker Model Monitor</strong>: Continuously monitors deployed models for performance and drift.","children":[],"payload":{"tag":"li","lines":"105,107"}}],"payload":{"tag":"li","lines":"104,107"}}],"payload":{"tag":"h3","lines":"84,85"}},{"content":"2. Algorithms for Tabular Data","children":[{"content":"<strong>XGBoost (Extreme Gradient Boosting)</strong>","children":[{"content":"<strong>Concept</strong>: A popular and efficient implementation of gradient-boosted decision trees.","children":[{"content":"<strong>Ensemble Learning</strong>: Combines multiple &quot;weak&quot; models to create one strong model.","children":[],"payload":{"tag":"li","lines":"110,111"}},{"content":"<strong>Boosting</strong>: A sequential technique where models are trained to correct the errors of their predecessors.","children":[],"payload":{"tag":"li","lines":"111,112"}},{"content":"<strong>Gradient Boosting</strong>: Uses gradient descent to minimize errors.","children":[],"payload":{"tag":"li","lines":"112,113"}}],"payload":{"tag":"li","lines":"109,113"}},{"content":"<strong>Problem Type</strong>: Classification &amp; Regression.","children":[],"payload":{"tag":"li","lines":"113,114"}},{"content":"<strong>Data Formats</strong>: <code>libsvm</code>, <code>CSV</code>, <code>parquet</code>, <code>protobuf</code>.","children":[],"payload":{"tag":"li","lines":"114,115"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"115,116"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_round</code>, <code>num_class</code>.","children":[],"payload":{"tag":"li","lines":"116,117"}},{"content":"<strong>Metrics</strong>: MAE, MSE, RMSE (Regression); Accuracy, AUC, F1 Score (Classification).","children":[],"payload":{"tag":"li","lines":"117,118"}},{"content":"<strong>Use Cases</strong>: Fraud detection, stock price prediction, customer churn, sales forecasting.","children":[],"payload":{"tag":"li","lines":"118,119"}}],"payload":{"tag":"li","lines":"108,119"}},{"content":"<strong>Linear Learner</strong>","children":[{"content":"<strong>Concept</strong>: A supervised algorithm for classification or regression, great for large, high-dimensional datasets. It fits a line to the data points by adjusting weights and biases using stochastic gradient descent.","children":[],"payload":{"tag":"li","lines":"120,121"}},{"content":"<strong>Problem Type</strong>: Classification &amp; Regression.","children":[],"payload":{"tag":"li","lines":"121,122"}},{"content":"<strong>Data Formats</strong>: <code>protobuf</code>, <code>CSV</code> for training. <code>JSON</code>, <code>protobuf</code>, <code>CSV</code> for inference.","children":[],"payload":{"tag":"li","lines":"122,123"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"123,124"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_classes</code>, <code>predictor_type</code>.","children":[],"payload":{"tag":"li","lines":"124,125"}},{"content":"<strong>Metrics</strong>: Cross-entropy loss, MAE, MSE (Regression); Precision, Recall, Accuracy (Classification).","children":[],"payload":{"tag":"li","lines":"125,126"}},{"content":"<strong>Use Cases</strong>: Loan application processing, email spam detection, recommendation systems.","children":[],"payload":{"tag":"li","lines":"126,127"}}],"payload":{"tag":"li","lines":"119,127"}},{"content":"<strong>K-Nearest Neighbor (KNN)</strong>","children":[{"content":"<strong>Concept</strong>: A non-parametric algorithm that classifies a data point based on its &quot;K&quot; closest neighbors. For regression, it averages their values; for classification, it uses a majority vote.","children":[],"payload":{"tag":"li","lines":"128,129"}},{"content":"<strong>Problem Type</strong>: Classification &amp; Regression.","children":[],"payload":{"tag":"li","lines":"129,130"}},{"content":"<strong>Data Formats</strong>: <code>protobuf</code>, <code>CSV</code> for training. <code>JSON</code>, <code>protobuf</code>, <code>CSV</code> for inference.","children":[],"payload":{"tag":"li","lines":"130,131"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"131,132"}},{"content":"<strong>Required Hyperparameters</strong>: <code>feature_dim</code>, <code>k</code>, <code>predictor_type</code>, <code>sample_size</code>.","children":[],"payload":{"tag":"li","lines":"132,133"}},{"content":"<strong>Metrics</strong>: MSE (Regression); Accuracy (Classification).","children":[],"payload":{"tag":"li","lines":"133,134"}},{"content":"<strong>Use Cases</strong>: Credit risk rating, recommendation systems, fraud detection.","children":[],"payload":{"tag":"li","lines":"134,135"}}],"payload":{"tag":"li","lines":"127,135"}},{"content":"<strong>Factorization Machines</strong>","children":[{"content":"<strong>Concept</strong>: An extension of a linear model designed to capture higher-order (pairwise) feature interactions in sparse datasets.","children":[],"payload":{"tag":"li","lines":"136,137"}},{"content":"<strong>Problem Type</strong>: Binary Classification &amp; Regression.","children":[],"payload":{"tag":"li","lines":"137,138"}},{"content":"<strong>Limitations</strong>: Only considers pairwise features, does not support multiclass problems or CSV format, performs poorly on dense data.","children":[],"payload":{"tag":"li","lines":"138,139"}},{"content":"<strong>Data Formats</strong>: <code>protobuf</code> (float32 tensors) only for training. <code>JSON</code>, <code>protobuf</code> for inference.","children":[],"payload":{"tag":"li","lines":"139,140"}},{"content":"<strong>Compute</strong>: Recommended for CPU only.","children":[],"payload":{"tag":"li","lines":"140,141"}},{"content":"<strong>Required Hyperparameters</strong>: <code>feature_dim</code>, <code>num_factors</code>, <code>predictor_type</code>.","children":[],"payload":{"tag":"li","lines":"141,142"}},{"content":"<strong>Metrics</strong>: RMSE (Regression); Accuracy, Cross-entropy (Classification).","children":[],"payload":{"tag":"li","lines":"142,143"}},{"content":"<strong>Use Cases</strong>: Recommendation systems, ad-click prediction.","children":[],"payload":{"tag":"li","lines":"143,145"}}],"payload":{"tag":"li","lines":"135,145"}}],"payload":{"tag":"h3","lines":"107,108"}},{"content":"3. Algorithms for Time Series Data","children":[{"content":"<strong>DeepAR</strong>","children":[{"content":"<strong>Concept</strong>: A supervised algorithm using RNNs for forecasting one-dimensional time series data. Can learn from multiple related time series to solve the &quot;cold start problem&quot; for new products.","children":[],"payload":{"tag":"li","lines":"147,148"}},{"content":"<strong>Forecast Types</strong>: Point-in-time (single value) and Probabilistic (range of values).","children":[],"payload":{"tag":"li","lines":"148,149"}},{"content":"<strong>Data Format</strong>: <code>JSON Lines</code> format (can be GZIP or Parquet). Requires <code>start</code> and <code>target</code> fields.","children":[],"payload":{"tag":"li","lines":"149,150"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"150,151"}},{"content":"<strong>Required Hyperparameters</strong>: <code>context_length</code>, <code>epochs</code>, <code>prediction_length</code>, <code>time_freq</code>.","children":[],"payload":{"tag":"li","lines":"151,152"}},{"content":"<strong>Metrics</strong>: RMSE, <code>wQuantileLoss</code>.","children":[],"payload":{"tag":"li","lines":"152,153"}},{"content":"<strong>Use Cases</strong>: Demand/sales forecasting, financial forecasting, risk assessment.","children":[],"payload":{"tag":"li","lines":"153,155"}}],"payload":{"tag":"li","lines":"146,155"}}],"payload":{"tag":"h3","lines":"145,146"}},{"content":"4. Algorithms for Unsupervised Learning","children":[{"content":"<strong>Principal Component Analysis (PCA)</strong>","children":[{"content":"<strong>Concept</strong>: Reduces the number of features (dimensionality) in a dataset by creating new, uncorrelated features called &quot;components&quot; that capture the most variance.","children":[],"payload":{"tag":"li","lines":"157,158"}},{"content":"<strong>Problem Type</strong>: Dimensionality Reduction.","children":[],"payload":{"tag":"li","lines":"158,159"}},{"content":"<strong>Modes</strong>: <code>regular</code> (for sparse data) and <code>randomized</code> (for large datasets).","children":[],"payload":{"tag":"li","lines":"159,160"}},{"content":"<strong>Data Formats</strong>: <code>CSV</code>, <code>protobuf</code> for training. <code>JSON</code> for inference.","children":[],"payload":{"tag":"li","lines":"160,161"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"161,162"}},{"content":"<strong>Required Hyperparameters</strong>: <code>feature_dim</code>, <code>mini_batch_size</code>, <code>num_components</code>.","children":[],"payload":{"tag":"li","lines":"162,163"}},{"content":"<strong>Use Cases</strong>: Image compression, financial analysis, customer feedback analysis.","children":[],"payload":{"tag":"li","lines":"163,164"}}],"payload":{"tag":"li","lines":"156,164"}},{"content":"<strong>Random Cut Forest (RCF)</strong>","children":[{"content":"<strong>Concept</strong>: Detects anomalies (outliers) by building an ensemble of trees. Data points that are easily isolated with fewer &quot;cuts&quot; are assigned a higher anomaly score.","children":[],"payload":{"tag":"li","lines":"165,166"}},{"content":"<strong>Problem Type</strong>: Anomaly Detection.","children":[],"payload":{"tag":"li","lines":"166,167"}},{"content":"<strong>Data Formats</strong>: <code>protobuf</code>, <code>CSV</code>.","children":[],"payload":{"tag":"li","lines":"167,168"}},{"content":"<strong>Compute</strong>: Recommended for CPU only.","children":[],"payload":{"tag":"li","lines":"168,169"}},{"content":"<strong>Required Hyperparameters</strong>: <code>feature_dim</code>.","children":[],"payload":{"tag":"li","lines":"169,170"}},{"content":"<strong>Metrics</strong>: F1 Score.","children":[],"payload":{"tag":"li","lines":"170,171"}},{"content":"<strong>Use Cases</strong>: Fraud detection, security breach detection, monitoring bot activity.","children":[],"payload":{"tag":"li","lines":"171,172"}}],"payload":{"tag":"li","lines":"164,172"}},{"content":"<strong>IP Insights</strong>","children":[{"content":"<strong>Concept</strong>: Learns usage patterns for IPv4 addresses by associating them with entities (e.g., user IDs). Uses a neural network to detect anomalous logins from unusual IP addresses or locations.","children":[],"payload":{"tag":"li","lines":"173,174"}},{"content":"<strong>Problem Type</strong>: Anomaly Detection.","children":[],"payload":{"tag":"li","lines":"174,175"}},{"content":"<strong>Data Formats</strong>: <code>CSV</code> for training. <code>CSV</code>, <code>JSON</code>, <code>JSON Lines</code> for inference.","children":[],"payload":{"tag":"li","lines":"175,176"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"176,177"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_entity_vectors</code>, <code>vector_dim</code>.","children":[],"payload":{"tag":"li","lines":"177,178"}},{"content":"<strong>Metrics</strong>: Area Under Curve (AUC).","children":[],"payload":{"tag":"li","lines":"178,179"}},{"content":"<strong>Use Cases</strong>: Detecting fraudulent transactions/account takeovers, compliance checks, geolocation-based personalization.","children":[],"payload":{"tag":"li","lines":"179,180"}}],"payload":{"tag":"li","lines":"172,180"}},{"content":"<strong>K-Means</strong>","children":[{"content":"<strong>Concept</strong>: Groups data into a pre-determined number (<code>K</code>) of clusters. It iteratively assigns data points to the nearest cluster centroid and then recalculates the centroid.","children":[],"payload":{"tag":"li","lines":"181,182"}},{"content":"<strong>Problem Type</strong>: Clustering.","children":[],"payload":{"tag":"li","lines":"182,183"}},{"content":"<strong>Data Formats</strong>: <code>CSV</code>, <code>protobuf</code> for training. <code>JSON</code> for inference.","children":[],"payload":{"tag":"li","lines":"183,184"}},{"content":"<strong>Compute</strong>: Recommends CPU (GPU supported for single instance only).","children":[],"payload":{"tag":"li","lines":"184,185"}},{"content":"<strong>Required Hyperparameters</strong>: <code>feature_dim</code>, <code>K</code>.","children":[],"payload":{"tag":"li","lines":"185,186"}},{"content":"<strong>Metrics</strong>: Mean Square Distance (msd), Sum of Square Distance (ssd).","children":[],"payload":{"tag":"li","lines":"186,187"}},{"content":"<strong>Use Cases</strong>: Customer segmentation, market segmentation, recommendation systems.","children":[],"payload":{"tag":"li","lines":"187,189"}}],"payload":{"tag":"li","lines":"180,189"}}],"payload":{"tag":"h3","lines":"155,156"}},{"content":"5. Algorithms for Text Data (NLP)","children":[{"content":"<strong>Object2Vec</strong>","children":[{"content":"<strong>Concept</strong>: A customizable neural embedding algorithm that creates vector representations of objects (e.g., words, sentences, users, products) by learning from their relationships.","children":[],"payload":{"tag":"li","lines":"191,192"}},{"content":"<strong>Problem Type</strong>: General Purpose Embedding.","children":[],"payload":{"tag":"li","lines":"192,193"}},{"content":"<strong>Data Formats</strong>: <code>JSON Lines</code> (sentence-sentence or label-sentence pairs) for training. <code>JSON</code> for inference.","children":[],"payload":{"tag":"li","lines":"193,194"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"194,195"}},{"content":"<strong>Required Hyperparameters</strong>: <code>enc0_max_seq_len</code>, <code>enc0_vocab_size</code>.","children":[],"payload":{"tag":"li","lines":"195,196"}},{"content":"<strong>Metrics</strong>: MSE (Regression); Accuracy, Cross-entropy (Classification).","children":[],"payload":{"tag":"li","lines":"196,197"}},{"content":"<strong>Use Cases</strong>: User behavior analysis, sentiment analysis, social network analysis.","children":[],"payload":{"tag":"li","lines":"197,198"}}],"payload":{"tag":"li","lines":"190,198"}},{"content":"<strong>Latent Dirichlet Allocation (LDA)</strong>","children":[{"content":"<strong>Concept</strong>: An unsupervised generative probabilistic model that discovers underlying topics in a collection of documents.","children":[],"payload":{"tag":"li","lines":"199,200"}},{"content":"<strong>Problem Type</strong>: Topic Modeling.","children":[],"payload":{"tag":"li","lines":"200,201"}},{"content":"<strong>Data Formats</strong>: <code>CSV</code>, <code>protobuf</code> for training. <code>JSON</code> for inference.","children":[],"payload":{"tag":"li","lines":"201,202"}},{"content":"<strong>Compute</strong>: Supports single-instance CPU only.","children":[],"payload":{"tag":"li","lines":"202,203"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_topics</code>, <code>feature_dim</code>, <code>mini_batch_size</code>.","children":[],"payload":{"tag":"li","lines":"203,204"}},{"content":"<strong>Metrics</strong>: Per-Word-Log-Likelihood (pwll).","children":[],"payload":{"tag":"li","lines":"204,205"}},{"content":"<strong>Use Cases</strong>: Customer feedback analysis, social media trend analysis, content creation ideas.","children":[],"payload":{"tag":"li","lines":"205,206"}}],"payload":{"tag":"li","lines":"198,206"}},{"content":"<strong>Neural Topic Model (NTM)</strong>","children":[{"content":"<strong>Concept</strong>: An unsupervised algorithm, similar to LDA, but uses a neural network to model topics. More scalable than LDA but can be less interpretable.","children":[],"payload":{"tag":"li","lines":"207,208"}},{"content":"<strong>Problem Type</strong>: Topic Modeling.","children":[],"payload":{"tag":"li","lines":"208,209"}},{"content":"<strong>Data Formats</strong>: <code>CSV</code>, <code>protobuf</code> for training. <code>JSON</code>, <code>JSON Lines</code> for inference.","children":[],"payload":{"tag":"li","lines":"209,210"}},{"content":"<strong>Compute</strong>: Supports CPU &amp; GPU.","children":[],"payload":{"tag":"li","lines":"210,211"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_topics</code>, <code>feature_dim</code>.","children":[],"payload":{"tag":"li","lines":"211,212"}},{"content":"<strong>Metrics</strong>: Total loss.","children":[],"payload":{"tag":"li","lines":"212,213"}},{"content":"<strong>Use Cases</strong>: Uncovering customer pain points, personalized content recommendations, market sentiment analysis.","children":[],"payload":{"tag":"li","lines":"213,214"}}],"payload":{"tag":"li","lines":"206,214"}},{"content":"<strong>BlazingText</strong>","children":[{"content":"<strong>Concept</strong>: A highly optimized implementation of <code>Word2Vec</code> (unsupervised) and <code>FastText</code> (supervised text classification). Significantly faster than original implementations.","children":[],"payload":{"tag":"li","lines":"215,216"}},{"content":"<strong>Modes</strong>: <code>word2vec</code> (cbow, skip-gram) and <code>text classification</code>.","children":[],"payload":{"tag":"li","lines":"216,217"}},{"content":"<strong>Data Formats</strong>: A single preprocessed text file (space-separated tokens). <code>JSON</code> for inference.","children":[],"payload":{"tag":"li","lines":"217,218"}},{"content":"<strong>Compute</strong>: Supports single CPU/GPU; multiple CPUs for batch_skip-gram.","children":[],"payload":{"tag":"li","lines":"218,219"}},{"content":"<strong>Required Hyperparameters</strong>: <code>mode</code>.","children":[],"payload":{"tag":"li","lines":"219,220"}},{"content":"<strong>Metrics</strong>: <code>mean_rho</code> (Word2Vec); Accuracy (Text Classification).","children":[],"payload":{"tag":"li","lines":"220,221"}},{"content":"<strong>Use Cases</strong>: Sentiment analysis, document classification, recommendation systems.","children":[],"payload":{"tag":"li","lines":"221,222"}}],"payload":{"tag":"li","lines":"214,222"}},{"content":"<strong>Sequence-to-Sequence (Seq2Seq)</strong>","children":[{"content":"<strong>Concept</strong>: A supervised algorithm that transforms an input sequence to an output sequence using an encoder-decoder neural network architecture.","children":[],"payload":{"tag":"li","lines":"223,224"}},{"content":"<strong>Problem Type</strong>: Language Processing (Translation, Summarization).","children":[],"payload":{"tag":"li","lines":"224,225"}},{"content":"<strong>Data Formats</strong>: <code>protobuf</code> for training. <code>JSON</code>, <code>protobuf</code> for inference.","children":[],"payload":{"tag":"li","lines":"225,226"}},{"content":"<strong>Compute</strong>: Supports single-machine GPU only.","children":[],"payload":{"tag":"li","lines":"226,227"}},{"content":"<strong>Required Hyperparameters</strong>: None.","children":[],"payload":{"tag":"li","lines":"227,228"}},{"content":"<strong>Metrics</strong>: Accuracy, BLEU score, Perplexity.","children":[],"payload":{"tag":"li","lines":"228,229"}},{"content":"<strong>Use Cases</strong>: Machine translation, speech-to-text conversion, code generation.","children":[],"payload":{"tag":"li","lines":"229,231"}}],"payload":{"tag":"li","lines":"222,231"}}],"payload":{"tag":"h3","lines":"189,190"}},{"content":"6. Algorithms for Image Data","children":[{"content":"<strong>Image Classification</strong>","children":[{"content":"<strong>Concept</strong>: A supervised algorithm that classifies an entire image into one or more categories. Uses a Convolutional Neural Network (CNN).","children":[],"payload":{"tag":"li","lines":"233,234"}},{"content":"<strong>Modes</strong>: <code>Full training</code> (from scratch) or <code>Transfer learning</code> (using pre-trained weights).","children":[],"payload":{"tag":"li","lines":"234,235"}},{"content":"<strong>Data Formats</strong>: <code>recordIO</code> or image formats (<code>JPG</code>, <code>PNG</code>), plus a <code>.lst</code> file listing images.","children":[],"payload":{"tag":"li","lines":"235,236"}},{"content":"<strong>Compute</strong>: Recommends GPU for training.","children":[],"payload":{"tag":"li","lines":"236,237"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_classes</code>, <code>num_training_samples</code>.","children":[],"payload":{"tag":"li","lines":"237,238"}},{"content":"<strong>Metrics</strong>: Accuracy.","children":[],"payload":{"tag":"li","lines":"238,239"}},{"content":"<strong>Use Cases</strong>: Medical image diagnosis (X-rays), classifying objects for autonomous vehicles, security surveillance.","children":[],"payload":{"tag":"li","lines":"239,240"}}],"payload":{"tag":"li","lines":"232,240"}},{"content":"<strong>Object Detection</strong>","children":[{"content":"<strong>Concept</strong>: Goes beyond classification to identify and locate <em>multiple</em> objects within a single image by drawing bounding boxes around them. Uses Single Shot MultiBox Detector (SSD) framework.","children":[],"payload":{"tag":"li","lines":"241,242"}},{"content":"<strong>Data Formats</strong>: <code>recordIO</code> or image formats (<code>JPG</code>, <code>PNG</code>), with a matching <code>.json</code> file for each image&apos;s annotations.","children":[],"payload":{"tag":"li","lines":"242,243"}},{"content":"<strong>Compute</strong>: Recommends GPU for training.","children":[],"payload":{"tag":"li","lines":"243,244"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_classes</code>, <code>num_training_samples</code>.","children":[],"payload":{"tag":"li","lines":"244,245"}},{"content":"<strong>Metrics</strong>: Mean Average Precision (mAP).","children":[],"payload":{"tag":"li","lines":"245,246"}},{"content":"<strong>Use Cases</strong>: Automated retail checkout systems, manufacturing quality control, scanning information from documents.","children":[],"payload":{"tag":"li","lines":"246,247"}}],"payload":{"tag":"li","lines":"240,247"}},{"content":"<strong>Semantic Segmentation</strong>","children":[{"content":"<strong>Concept</strong>: The most granular image task, assigning a class label to <em>every single pixel</em> in an image to understand object shapes. The output is a segmentation mask.","children":[],"payload":{"tag":"li","lines":"248,249"}},{"content":"<strong>Data Formats</strong>: Requires separate channels for <code>train</code>, <code>validation</code> images (<code>JPG</code>) and their corresponding <code>train_annotation</code>, <code>validation_annotation</code> label images (<code>PNG</code>).","children":[],"payload":{"tag":"li","lines":"249,250"}},{"content":"<strong>Compute</strong>: Recommends GPU for training.","children":[],"payload":{"tag":"li","lines":"250,251"}},{"content":"<strong>Required Hyperparameters</strong>: <code>num_classes</code>, <code>num_training_samples</code>.","children":[],"payload":{"tag":"li","lines":"251,252"}},{"content":"<strong>Metrics</strong>: Mean Intersection-over-Union (mIOU), Pixel Accuracy.","children":[],"payload":{"tag":"li","lines":"252,253"}},{"content":"<strong>Use Cases</strong>: Analyzing satellite imagery, retail shelf analysis, content moderation in media.","children":[],"payload":{"tag":"li","lines":"253,255"}}],"payload":{"tag":"li","lines":"247,255"}}],"payload":{"tag":"h3","lines":"231,232"}}],"payload":{"tag":"h2","lines":"82,83"}},{"content":"Task Statement 3.3: Model Training &amp; Optimization","children":[{"content":"1. Splitting Data","children":[{"content":"<strong>Training Data</strong>: Used to train the model.","children":[],"payload":{"tag":"li","lines":"260,261"}},{"content":"<strong>Validation Data</strong>: Measures performance during training to tune hyperparameters.","children":[],"payload":{"tag":"li","lines":"261,262"}},{"content":"<strong>Testing Data</strong>: Determines how well the model generalizes to unseen data.","children":[],"payload":{"tag":"li","lines":"262,263"}},{"content":"<strong>Cross-Validation</strong>: Validating the model against fresh data using techniques like K-fold or Stratified K-fold.","children":[],"payload":{"tag":"li","lines":"263,265"}}],"payload":{"tag":"h3","lines":"259,260"}},{"content":"2. Optimization Techniques","children":[{"content":"<strong>Loss Function</strong>: Measures the difference between predicted and actual output.","children":[],"payload":{"tag":"li","lines":"266,267"}},{"content":"<strong>Gradient Descent</strong>: A common technique to minimize the loss function.","children":[],"payload":{"tag":"li","lines":"267,269"}}],"payload":{"tag":"h3","lines":"265,266"}},{"content":"3. Choosing Compute Resources","children":[{"content":"<strong>CPUs</strong>: Good for simpler models, small datasets, and budget constraints.","children":[],"payload":{"tag":"li","lines":"270,271"}},{"content":"<strong>GPUs</strong>: Good for complex deep learning models, large datasets, and high performance needs.","children":[],"payload":{"tag":"li","lines":"271,272"}},{"content":"<strong>Distributed Training</strong>: For very large models/datasets (SageMaker offers Data &amp; Model Parallelism).","children":[],"payload":{"tag":"li","lines":"272,274"}}],"payload":{"tag":"h3","lines":"269,270"}},{"content":"4. Updating &amp; Retraining Models","children":[{"content":"<strong>Importance</strong>: Retraining with new data keeps models accurate.","children":[],"payload":{"tag":"li","lines":"275,276"}},{"content":"<strong>Amazon SageMaker Canvas</strong>: Offers a no-code UI for scheduling model updates.","children":[],"payload":{"tag":"li","lines":"276,278"}}],"payload":{"tag":"h3","lines":"274,275"}}],"payload":{"tag":"h2","lines":"257,258"}},{"content":"Task Statement 3.4: Hyperparameter Tuning &amp; Model Concepts","children":[{"content":"1. Regularization","children":[{"content":"<strong>Goal</strong>: Prevent overfitting.","children":[],"payload":{"tag":"li","lines":"283,284"}},{"content":"<strong>Techniques</strong>: L1, L2, Early Stopping.","children":[],"payload":{"tag":"li","lines":"284,286"}}],"payload":{"tag":"h3","lines":"282,283"}},{"content":"2. Cross-Validation","children":[{"content":"<strong>Goal</strong>: Prevent overfitting by assessing performance on different data subsets.","children":[],"payload":{"tag":"li","lines":"287,288"}},{"content":"<strong>Techniques</strong>: K-fold, Stratified K-fold, Time Series split.","children":[],"payload":{"tag":"li","lines":"288,290"}}],"payload":{"tag":"h3","lines":"286,287"}},{"content":"3. Initializing Models for Tuning","children":[{"content":"<strong>Process</strong>: Define ranges (Categorical, Continuous, Integer) for hyperparameters for tuning jobs to search over.","children":[],"payload":{"tag":"li","lines":"291,293"}}],"payload":{"tag":"h3","lines":"290,291"}},{"content":"4. Neural Network Architecture","children":[{"content":"<strong>Components</strong>: Input Layer, Hidden Layer(s), Output Layer.","children":[],"payload":{"tag":"li","lines":"294,295"}},{"content":"<strong>Key Concepts</strong>: Weights, Biases, Activation Functions (ReLU, Softmax).","children":[],"payload":{"tag":"li","lines":"295,297"}}],"payload":{"tag":"h3","lines":"293,294"}},{"content":"5. Understanding Tree-Based Models","children":[{"content":"<strong>Structure</strong>: Root Node, Sub-nodes, Branches, Leaf Nodes.","children":[],"payload":{"tag":"li","lines":"298,299"}},{"content":"<strong>Key Hyperparameters</strong>: <code>max_depth</code>, <code>min_samples_split</code>.","children":[],"payload":{"tag":"li","lines":"299,301"}}],"payload":{"tag":"h3","lines":"297,298"}},{"content":"6. Understanding Linear Models","children":[{"content":"<strong>Key Hyperparameters</strong>: Learning Rate, Alpha (regularization strength).","children":[],"payload":{"tag":"li","lines":"302,304"}}],"payload":{"tag":"h3","lines":"301,302"}}],"payload":{"tag":"h2","lines":"280,281"}},{"content":"Task Statement 3.5: Model Evaluation","children":[{"content":"1. Evaluate Metrics","children":[{"content":"<strong>Classification</strong>: Accuracy, Precision, Recall, F1 Score, AUC Curve.","children":[],"payload":{"tag":"li","lines":"309,310"}},{"content":"<strong>Regression</strong>: MAE, MSE, RMSE.","children":[],"payload":{"tag":"li","lines":"310,312"}}],"payload":{"tag":"h3","lines":"308,309"}},{"content":"2. Interpret Confusion Matrices","children":[{"content":"<strong>Purpose</strong>: A table showing the performance of a classification model.","children":[],"payload":{"tag":"li","lines":"313,314"}},{"content":"<strong>Components</strong>: True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN).","children":[],"payload":{"tag":"li","lines":"314,316"}}],"payload":{"tag":"h3","lines":"312,313"}},{"content":"3. Online and Offline Model Evaluation","children":[{"content":"<strong>Online Evaluation (A/B Testing)</strong>: Assessing model performance on live data in production.","children":[],"payload":{"tag":"li","lines":"317,319"}}],"payload":{"tag":"h3","lines":"316,317"}},{"content":"4. Compare ML Models","children":[{"content":"<strong>Consider</strong>: Computational Complexity (Time, Space), Sample Complexity.","children":[],"payload":{"tag":"li","lines":"320,321"}}],"payload":{"tag":"h3","lines":"319,320"}}],"payload":{"tag":"h2","lines":"306,307"}}],"payload":{"tag":"h1","lines":"8,9"}},{"colorFreezeLevel":2,"initialExpandLevel":2,"maxWidth":350})</script>
</body>
</html>
