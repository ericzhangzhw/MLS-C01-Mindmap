---
title: Enhanced AWS ML Module Review
markmap:
  colorFreezeLevel: 2
  initialExpandLevel: 2
  maxWidth: 300
---

# Enhanced AWS ML Module Review

- ## 1. ML Implementation & Operations
  - ### Data Ingestion & Transformation
    - **AWS Kinesis**: Collect and process streaming data in real-time.
    - **AWS Glue**: An ETL (extract, transform, load) service to prepare and integrate data from various sources (S3, RDS, etc.).
    - **Amazon EMR**: Process and analyze big data using frameworks like Apache Hadoop, Spark, and Hive.
  - ### Model Deployment Strategies
    - #### **SageMaker Hosted Endpoints** (Real-time Inference)
      - The easiest way to deploy a model.
      - Creates a persistent HTTPS endpoint for on-demand predictions.
      - **How it works**: Deploys a model to a container on **ECS**, running on **EC2**. Fully managed by SageMaker.
      - **Deployment**: Use the `deploy()` method in the Python SDK.
    - #### **SageMaker Serverless Inference**
      - **Use Case**: For workloads with intermittent or unpredictable traffic and idle periods.
      - **Benefit**: Pay-per-use, automatically scales compute resources. Can tolerate cold starts.
    - #### **SageMaker Batch Transform**
      - **Use Case**: Run inference on an entire dataset at once (offline).
      - **Benefit**: No persistent endpoint needed. Manages provisioning and de-provisioning of resources.
      - Can also be used to pre-process datasets or associate input records with inference results.
    - #### **Manual Deployment Options**
      - **EC2 Instance**: Use **Deep Learning AMIs** (pre-configured with frameworks like TensorFlow, PyTorch) and select a powerful instance type (e.g., P5 with GPUs).
      - **Custom Container on ECS**: Build your own Docker container and deploy it on Elastic Container Service for full control.
  - ### Scalability & Resiliency
    - #### **High Availability & Fault Tolerance**
      - **Goal**: Avoid single points of failure. Design for failure ("Everything fails all the time").
      - **Method**: Deploy resources to multiple locations.
        - Multiple **Availability Zones (AZs)** to protect against instance/AZ failure.
        - Multiple **Regions** to protect against regional failure.
      - **Best Practice**: Use a greater number of smaller instance types instead of fewer larger ones to minimize the impact of a single instance failure.
      - **Reference**: AWS Well-Architected Framework.
    - #### **Auto Scaling Model Endpoints**
      - **How it works**: Automatically adjusts the number of instances in response to traffic.
      - **Configuration**: Define a scaling policy based on a metric, such as `SageMakerVariantInvocationsPerInstance`.
      - SageMaker automatically load balances requests across all instances.
    - #### **Multi-Model Endpoints**
      - **Use Case**: Host many models that use the same ML framework on one shared container.
      - **Benefits**:
        - **Cost-Effective**: Improves container utilization, avoiding a new endpoint for each model.
        - **Reduced Overhead**: Manage one endpoint instead of many.
  - ### Model Testing in Production
    - #### **A/B Testing (Production Variants)**
      - **Method**: Distribute traffic to multiple model versions on the same endpoint.
      - **Configuration**: Assign a **weight** to each **production variant** (e.g., 20% to model A, 80% to model B).
      - **Updating**: Weights can be updated without any application code changes.
      - **Direct Invocation**: Call a specific model version using the `TargetVariant` parameter.
  - ### Service Quotas (Limits)
    - Limits exist on services (e.g., number of specific EC2 instances).
    - Can impact SageMaker jobs (e.g., Batch Transform).
    - **Management**:
      - Request quota increases in the AWS Console.
      - Check limits with **Trusted Advisor**.

- ## 2. Security & Identity
  - ### Identity & Access Management (IAM)
    - **Principle of Least Privilege**: Grant only the permissions an entity needs to perform its function.
    - **SageMaker Execution Roles**: An IAM role that grants SageMaker permission to perform operations on your behalf.
      - The default `AmazonSagemakerFullAccess` policy is broad; it's best practice to create restrictive, custom policies.
  - ### Data & Network Protection
    - #### **Amazon S3 Security**
      - **Default**: All S3 buckets are **private**.
      - **Bucket Policies**: Define fine-grained access permissions.
      - **Conditions**: Enforce rules, like requiring HTTPS.
    - #### **Encryption with AWS KMS**
      - **How it works**: Uses **Envelope Encryption**.
      - **Key Policies**: Control which users/roles can use keys.
      - **Critical**: The SageMaker Execution Role **must** have `encrypt` and `decrypt` permissions for any customer-managed KMS key it needs to use.
    - #### **VPC & Private Communication**
      - **VPC Endpoints (AWS PrivateLink)**: Enables **private and secure communication** between your VPC and AWS services. Traffic **never leaves the Amazon network**.
  - ### Other Security Concepts
    - **Data Anonymization**: Hashing values with Athena.
    - **Security Groups**: Stateful virtual firewall for EC2 instances.

- ## 3. MLOps, Monitoring & Governance
  - ### Monitoring vs. Auditing
    - #### **Amazon CloudWatch (Monitoring)**
      - **Purpose**: Monitors the **performance and health** of systems.
      - **Metrics**: Collects near-real-time utilization metrics (CPU, Memory, GPU).
      - **CloudWatch Logs**: Centralizes and stores log files.
      - **CloudWatch Events (EventBridge)**: Responds to system events (e.g., training job completion).
      - **CloudWatch Alarms**: Sends notifications (via SNS/SES) when a metric breaches a threshold.
    - #### **AWS CloudTrail (Auditing)**
      - **Purpose**: Provides a **governance and audit trail** of API calls.
      - **What it logs**: Actions like `CreateTrainingJob`, `CreateModel`.
      - **Long-term storage**: Create a **trail** to save logs indefinitely to an S3 bucket.
  - ### SageMaker Algorithm Selection
    - #### **Supervised Learning**
      - **Classification (Binary/Multi-class)**: Linear Learner, k-NN, XGBoost, Factorization Machines.
      - **Regression**: Linear Learner, k-NN, XGBoost, Factorization Machines.
    - #### **Time-Series Forecasting**
      - **Algorithm**: DeepAR.
    - #### **Unsupervised Learning**
      - **Anomaly Detection**: Random Cut Forest.
      - **Clustering**: K-Means.
      - **Topic Modeling**: Latent Dirichlet Allocation (LDA), Neural Topic Model (NTM).
    - #### **Text Analysis**
      - **Text Classification**: BlazingText, Text Classification (TensorFlow).
      - **Translation / Summarization / Speech-to-Text**: Seq2Seq.
    - #### **Image & Computer Vision**
      - **Image Classification**: Based on MXNet.
      - **Object Detection**: Based on MXNet, TensorFlow.
      - **Pixel-level Categorization**: Semantic Segmentation.
  - ### Advanced Customization & Automation
    - #### **Custom Docker Containers**
      - **Use Case**: When a built-in algorithm doesn't fit your needs.
      - **Process**: Build a Docker image with your custom code/packages and push it to **Amazon ECR**.
    - #### **Golden Images (AMIs)**
      - A pre-configured EC2 image (OS, software, scripts).
      - Ensures consistency and is used with Auto Scaling.
    - #### **Retraining Pipelines with AWS Step Functions**
      - Orchestrate and automate the entire ML workflow.
  - ### SageMaker Model Monitor
    - **Purpose**: Continuously monitor a deployed model for drift.
    - **Detects Drift In**: Data Quality, Model Quality, Bias, and Feature Attribution.

- ## 4. AWS AI/ML Service Landscape
  - ### The AWS Machine Learning Stack (3 Layers)
    - #### **Bottom Layer: Infrastructure & Frameworks**
      - **For**: ML experts wanting full control.
      - **Services**: EC2 (w/ GPUs), ECS, Deep Learning AMIs, Docker.
    - #### **Middle Layer: Amazon SageMaker**
      - **For**: Developers and data scientists wanting to streamline the ML lifecycle.
    - #### **Top Layer: AI/ML Services**
      - **For**: Customers wanting to add intelligence to apps without building/training models.
  - ### High-Level AI Service Details
    - #### **Text & Document Analysis**
      - **Textract**: Extracts text and structured data from documents (PDFs, images, forms) using OCR. Use for ID processing or invoice analysis.
      - **Comprehend**: Uses NLP to discover insights in text. Performs sentiment analysis, identifies key phrases, topics, and language.
    - #### **Speech & Language**
      - **Transcribe**: Speech-to-text service. Takes audio files or streams as input.
      - **Translate**: Neural machine translation for large volumes of text or HTML. Supports over 70 languages.
      - **Polly**: Text-to-speech service that generates natural-sounding audio.
      - **Lex**: Builds conversational interfaces (chatbots) using natural language understanding (NLU).
    - #### **Vision**
      - **Rekognition**: Image and video analysis to detect objects, people, text, scenes, and activities.
    - #### **Forecasting & Fraud**
      - **Forecast**: Time-series forecasting service. Uses historical data to predict future demand (e.g., for retail, staffing).
      - **Fraud Detector**: Builds custom fraud detection models based on your historical data for low-latency, real-time online fraud prevention.